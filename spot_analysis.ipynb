{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Spot resources Analytics\n",
    "\n",
    "Here we perform some initial process and analysis on the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With static dataset, e.g. load the grabbed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r3.large' 'm3.medium' 'g2.2xlarge' 'r3.xlarge' 'c3.2xlarge' 'c3.xlarge'\n",
      " 'm3.2xlarge' 'm3.large' 'm3.xlarge' 'c3.8xlarge' 'c3.large' 'c3.4xlarge'\n",
      " 't1.micro' 'r3.4xlarge' 'm1.small' 'r3.2xlarge']\n",
      "['ap-southeast-2b' 'us-east-1e' 'us-east-1a' 'us-east-1d' 'ap-southeast-2a'\n",
      " 'sa-east-1a' 'us-east-1b' 'us-west-1a' 'us-west-1b' 'us-west-2a'\n",
      " 'us-west-2b' 'eu-west-1a' 'us-west-2c' 'ap-northeast-1c' 'ap-northeast-1a'\n",
      " 'sa-east-1b' 'ap-southeast-1a' 'eu-west-1c' 'eu-west-1b' 'ap-southeast-1b'\n",
      " 'ap-northeast-1b' 'sa-east-1c']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# parse the data file and extra the results\n",
    "filename = 'data1'\n",
    "\n",
    "df = pd.read_csv(filename, sep=\"\\t\", header = None)\n",
    "df.columns = [\"info\", \"SpotPrice\", \"TimeStamp\", \"InstanceType\", \"OS type\", \"AvailabilityZone\"]\n",
    "df['TimeStamp'] =pd.to_datetime(df.TimeStamp)\n",
    "\n",
    "df.index = df.TimeStamp\n",
    "df = df.drop('info', 1).drop(['OS type'],axis=1)\n",
    "df = df.drop(['TimeStamp'],axis=1).sort_index()\n",
    " \n",
    "\n",
    "df.head(15)\n",
    "print (df['InstanceType'].unique())\n",
    "print (df['AvailabilityZone'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance_types  = ['c3.xlarge', 'c3.2xlarge', 'c3.4xlarge', 'c3.8xlarge']\n",
    "region = 'us-east-1'\n",
    "\n",
    "df1 = df[df.AvailabilityZone == 'us-west-1a']\n",
    "df2 = df1[df1.InstanceType == 'c3.8xlarge']\n",
    "df2.to_csv('us-east-1a_c3-8xlarge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\n",
    "    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(grp.index, grp['SpotPrice'], label=key)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.title('Spot Pricing - ' + k)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\n",
    "    #plt.figure(1, figsize(20,5))\n",
    "    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.hist(grp['SpotPrice'], bins=100, label=key,)\n",
    "        plt.xlim([0, 1])\n",
    "        #grp.groupby(grp.index.dayofweek).agg(['mean']).plot()\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of Spot Pricing - ' + k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we grad dataset from AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance_types  = ['c3.xlarge', 'c3.2xlarge', 'c3.4xlarge', 'c3.8xlarge']\n",
    "region = 'us-east-1'\n",
    "number_of_days = 10\n",
    "\n",
    "end = !date -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "end = end[0]\n",
    "start = !date -v-{number_of_days}d -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "#start = !date -v-{number_of_days}d\" -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "#print(start)\n",
    "start = start[0]\n",
    "print (\"will process from \" + start + \" to \" + end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto as boto\n",
    "import boto.ec2 as ec2\n",
    "import datetime, time\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.mpl_style', 'default')  # Make the graphs a bit prettier\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "ec2 = boto.ec2.connect_to_region(region)\n",
    "\n",
    "\n",
    "#\n",
    "# process the output and convert to a dataframe\n",
    "#\n",
    "\n",
    "l = []\n",
    "for instance in instance_types:\n",
    "    sys.stdout.write(\"*** processing \" + instance + \" ***\\n\")\n",
    "    sys.stdout.flush()\n",
    "    prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance)\n",
    "    for price in prices:\n",
    "        d = {'InstanceType': price.instance_type, \n",
    "             'AvailabilityZone': price.availability_zone, \n",
    "             'SpotPrice': price.price, \n",
    "             'Timestamp': price.timestamp}\n",
    "        l.append(d)\n",
    "    next = prices.next_token\n",
    "    while (next != ''):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "        prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance,\n",
    "                                            next_token=next )\n",
    "        for price in prices:\n",
    "            d = {'InstanceType': price.instance_type, \n",
    "                 'AvailabilityZone': price.availability_zone, \n",
    "                 'SpotPrice': price.price, \n",
    "                 'Timestamp': price.timestamp}\n",
    "            l.append(d)\n",
    "        next = prices.next_token\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "df = pd.DataFrame(l)\n",
    "df = df.set_index(pd.to_datetime(df['Timestamp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis #1\n",
    "**Problems:** Can we predict future price of a spot instance given previous history and how other vm’s are reacting?\n",
    "\n",
    "To achieve the goal of prediction, we are expecting to do pattern matching from the collected dataset. In this case, whenever users make a bid, we can based on the resources types, time or day, and the trending price to do pattern matching. We will be able to provide a prediction if we can shoot a pattern.\n",
    "\n",
    "Expecting tools are supervised and unsupervised learning algorithms, e.g. classification and\n",
    "clustering methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis #2\n",
    "\n",
    "For each machine type there exists a region that is more favorable to use, as the market volatility is very low and the prices tend to stay cheaper than the other regions.\n",
    "\n",
    "With in proving this hypothesis users will be able to find the best region they should be bidding in, as long as latency is not an issue for them.\n",
    "\n",
    "Data Science tools & Techniques: We can use clustering and classification methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-17 08:01:54\n",
      "2015-03-19 07:42:11\n",
      "60 days 23:40:17\n"
     ]
    }
   ],
   "source": [
    "print (df.index.min())\n",
    "print (df.index.max())\n",
    "print(df.index.max()- df.index.min()) \n",
    "#df = df.truncate(before='2015-01-16', after='2015-3-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.resample('H')\n",
    "df = df.fillna(\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex a non-unique index with a method or limit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-99d0b542b67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfSorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfSorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfSorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'H'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdfSorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfSorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ffill\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdfSorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfSorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'InstanceType'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AvailabilityZone'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksparakis/.conda/envs/py35/lib/python3.5/site-packages/pandas/tseries/resample.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, method, limit)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \"\"\"\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interpolate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_docs_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksparakis/.conda/envs/py35/lib/python3.5/site-packages/pandas/tseries/resample.py\u001b[0m in \u001b[0;36m_upsample\u001b[0;34m(self, method, limit)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             result = obj.reindex(res_index, method=method,\n\u001b[0;32m--> 704\u001b[0;31m                                  limit=limit)\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksparakis/.conda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, columns, **kwargs)\u001b[0m\n\u001b[1;32m   2739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m         return super(DataFrame, self).reindex(index=index, columns=columns,\n\u001b[0;32m-> 2741\u001b[0;31m                                               **kwargs)\n\u001b[0m\u001b[1;32m   2742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex_axis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksparakis/.conda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[0;32m-> 2229\u001b[0;31m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[0;32m/Users/ksparakis/.conda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   2685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2686\u001b[0m             frame = frame._reindex_index(index, method, copy, level,\n\u001b[0;32m-> 2687\u001b[0;31m                                          fill_value, limit, tolerance)\n\u001b[0m\u001b[1;32m   2688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksparakis/.conda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[0;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         new_index, indexer = self.index.reindex(new_index, method, level,\n\u001b[1;32m   2694\u001b[0m                                                 \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m                                                 tolerance=tolerance)\n\u001b[0m\u001b[1;32m   2696\u001b[0m         return self._reindex_with_indexers({0: [new_index, indexer]},\n\u001b[1;32m   2697\u001b[0m                                            \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksparakis/.conda/envs/py35/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   2340\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m                         raise ValueError(\"cannot reindex a non-unique index \"\n\u001b[0m\u001b[1;32m   2343\u001b[0m                                          \"with a method or limit\")\n\u001b[1;32m   2344\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex a non-unique index with a method or limit"
     ]
    }
   ],
   "source": [
    "#Create full time series and fill data\n",
    "dfSorted = df.groupby(['AvailabilityZone', 'InstanceType'])\n",
    "dfSorted = dfSorted.resample('H')\n",
    "dfSorted = dfSorted.fillna(\"ffill\")\n",
    "\n",
    "dfSorted=dfSorted.drop('InstanceType', axis=1).drop('AvailabilityZone', axis=1)\n",
    "\n",
    "dfSorted.to_csv(\"im.csv\")\n",
    "depa = pd.read_csv(\"im.csv\")\n",
    "depa = depa.groupby(['AvailabilityZone', 'InstanceType'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor name, group in depa:\\n    if name[0] ==\"ap-northeast-1a\":\\n        #group.index = group[\\'TimeStamp\\']\\n        #print(group.head(20))\\n        #group = group.truncate(before=\\'2015-01-18\\', after=\\'2015-3-17\\')\\n        d[name[1]]=group[\\'SpotPrice\\'].tolist()\\n        print(len(group[\\'SpotPrice\\'].tolist()))\\n'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouped_prices = [group['SpotPrice'].tolist() for name, group in depa]\n",
    "\n",
    "#dfer = dataframe\n",
    "d = {}\n",
    "\n",
    "count = 0\n",
    "#need to run through and get rid of rows where timestamp, spotprice data doesnt exist for the others\n",
    "for name, group in depa:\n",
    "    if count == 0:\n",
    "        d['TimeStamp']=group['TimeStamp'].tolist()\n",
    "    if name[0] ==\"ap-northeast-1a\":\n",
    "        for a in d['TimeStamp']+group['TimeStamp'].tolist():\n",
    "            if(a not in d['TimeStamp']):\n",
    "                group = group[group['TimeStamp'] != a]\n",
    "                print (a)\n",
    "            if(a not in group['TimeStamp'].tolist()):\n",
    "                d['TimeStamp'].remove(a)\n",
    "                print (a)\n",
    "    \n",
    "    \n",
    "    #seter = set(d['TimeStamp']) - set(group['TimeStamp'].tolist())\n",
    "    #print(seter)\n",
    "    #remove = list(seter)\n",
    "    #print(remove)    \n",
    "#dfer = pd.DataFrame(d)\n",
    "    \n",
    "#for name, group in depa:\n",
    "     #print(len(group['SpotPrice'].tolist()))\n",
    "        \n",
    "'''\n",
    "for name, group in depa:\n",
    "    if name[0] ==\"ap-northeast-1a\":\n",
    "        #group.index = group['TimeStamp']\n",
    "        #print(group.head(20))\n",
    "        #group = group.truncate(before='2015-01-18', after='2015-3-17')\n",
    "        d[name[1]]=group['SpotPrice'].tolist()\n",
    "        print(len(group['SpotPrice'].tolist()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'corr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-0f68c87c6f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#numpy.corrcoef(grouped_prices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrouped_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m '''\n\u001b[1;32m      5\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'corr'"
     ]
    }
   ],
   "source": [
    "#numpy.corrcoef(grouped_prices)\n",
    "\n",
    "grouped_prices.corr()\n",
    "'''\n",
    "mask = np.zeros_like(corr_df)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "seaborn.heatmap(corr_df, cmap='RdYlGn_r', vmax=1.0, vmin=-1.0 , mask = mask, linewidths=2.5)\n",
    "# Show the plot we reorient the labels for each column and row to make them easier to read.\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=90) \n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hypothesis #3\n",
    "\n",
    "There exists some kind of relation between what kind of virtual machines are turning into hotspots. Say that we establish a line as half price of EC2 instances, it makes sense to pay half price to gain usage of resources but probably not more than 3⁄4. By extracting patterns from the price history, we can study that whether or not there was the case that some resources were becoming hotspot in the spot instances market.\n",
    "\n",
    "Potential data science method for this one includes: Time Series, Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('us-east-1a_c3-8xlarge.csv')\n",
    "#df.head(400)\n",
    "df = df2\n",
    "df.describe()\n",
    "\n",
    "df.SpotPrice.plot(label='Spot Price of c3.8xlarge', figsize = (15,5))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "\n",
    "[pattern matching over time series data](http://stats.stackexchange.com/questions/136091/sequential-pattern-matching-in-time-series-data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
