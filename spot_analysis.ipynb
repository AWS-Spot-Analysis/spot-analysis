{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Spot resources Analytics\n",
    "\n",
    "Here we perform some initial process and analysis on the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With static dataset, e.g. load the grabbed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# parse the data file and extra the results\n",
    "filename = 'aws-spot-price-history/data-1397804701'\n",
    "\n",
    "df = pd.read_csv(filename, sep=\"\\t\", header = None)\n",
    "df.columns = [\"info\", \"Spot price\", \"Time\", \"Machine size\", \"OS type\", \"Region\"]\n",
    "df = df.drop('info', 1)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we grad dataset from AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance_types  = ['c3.xlarge', 'c3.2xlarge', 'c3.4xlarge', 'c3.8xlarge']\n",
    "region = 'us-east-1'\n",
    "number_of_days = 10\n",
    "\n",
    "end = !date -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "end = end[0]\n",
    "start = !date -v \"-{number_of_days}d\" -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "start = start[0]\n",
    "print (\"will process from \" + start + \" to \" + end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto as boto\n",
    "import boto.ec2 as ec2\n",
    "import datetime, time\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.mpl_style', 'default') # Make the graphs a bit prettier\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "ec2 = boto.ec2.connect_to_region(region)\n",
    "\n",
    "\n",
    "#\n",
    "# process the output and convert to a dataframe\n",
    "#\n",
    "\n",
    "l = []\n",
    "for instance in instance_types:\n",
    "    sys.stdout.write(\"*** processing \" + instance + \" ***\\n\")\n",
    "    sys.stdout.flush()\n",
    "    prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance)\n",
    "    for price in prices:\n",
    "        d = {'InstanceType': price.instance_type, \n",
    "             'AvailabilityZone': price.availability_zone, \n",
    "             'SpotPrice': price.price, \n",
    "             'Timestamp': price.timestamp}\n",
    "        l.append(d)\n",
    "    next = prices.next_token\n",
    "    while (next != ''):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "        prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance,\n",
    "                                            next_token=next )\n",
    "        for price in prices:\n",
    "            d = {'InstanceType': price.instance_type, \n",
    "                 'AvailabilityZone': price.availability_zone, \n",
    "                 'SpotPrice': price.price, \n",
    "                 'Timestamp': price.timestamp}\n",
    "            l.append(d)\n",
    "        next = prices.next_token\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "df = pd.DataFrame(l)\n",
    "df = df.set_index(pd.to_datetime(df['Timestamp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis #1\n",
    "**Problems:** Can we predict future price of a spot instance given previous history and how other vm’s are reacting?\n",
    "\n",
    "To achieve the goal of prediction, we are expecting to do pattern matching from the collected dataset. In this case, whenever users make a bid, we can based on the resources types, time or day, and the trending price to do pattern matching. We will be able to provide a prediction if we can shoot a pattern.\n",
    "\n",
    "Expecting tools are supervised and unsupervised learning algorithms, e.g. classification and\n",
    "clustering methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis #2\n",
    "\n",
    "For each machine type there exists a region that is more favorable to use, as the market volatility is very low and the prices tend to stay cheaper than the other regions.\n",
    "\n",
    "With in proving this hypothesis users will be able to find the best region they should be bidding in, as long as latency is not an issue for them.\n",
    "\n",
    "Data Science tools & Techniques: We can use clustering and classification methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hypothesis #3\n",
    "\n",
    "There exists some kind of relation between what kind of virtual machines are turning into hotspots. Say that we establish a line as half price of EC2 instances, it makes sense to pay half price to gain usage of resources but probably not more than 3⁄4. By extracting patterns from the price history, we can study that whether or not there was the case that some resources were becoming hotspot in the spot instances market.\n",
    "\n",
    "Potential data science method for this one includes: Time Series, Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i, f in enumerate(df[\"Filename\"]):\n",
    "    weight = x_wgt_pct(f)  # Note: you may have to slice off the 's i.e. f[1:-1]\n",
    "    df.ix[i, \"Weight\"] = weight\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "\n",
    "[pattern matching over time series data](http://stats.stackexchange.com/questions/136091/sequential-pattern-matching-in-time-series-data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
